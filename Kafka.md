**Использование Kafka:**
- Телеметрия
- K-архитектура
```
1. несколько событий или запросов данных заносятся в очередь для обработки в распределенном хранилище файловой системы или в истории;
2. порядок событий и запросов не предопределен — фреймворки потоковой обработки могут взаимодействовать с базой данных в любое время;
3. требуется устойчивость и высокая доступность, поскольку обработка данных канонического хранилища выполняется для каждого узла системы.
```
- Шина данных
- Интеграционная шина
-------------------------
- **Producer** - записывает данные в очередь
- **Consumer** - читает данные из очереди
- **Cluster** - кластер Kafka, может состоять из нескольких **Broker**

![изображение](https://github.com/terhia/interview/assets/7370741/d0d1d4a2-5ebe-4d78-8567-8a3787f5b93a)
- **Topic** - состоит из **Partition**
- **Partition** состоит из **Segment**, удалять данные из Kafka можно **Segment**'ами
- Данные записываются всегда в конец **Partition**

-------------------------

- **Segment** состоит из трёх файлов на диске

![изображение](https://github.com/terhia/interview/assets/7370741/48e71f3c-3e2a-49f6-b713-aa6fe189cee8)

-------------------------

- Сообщение можно быстро найти по **Offset**
- У каждой партиции свой **Leader**
- Producer пишет сообщения в **Leader**, дальше **Leader** пишет сообщения в реплику **ISR** (синхронизированные реплики)
- Данные реплицируются между **Broker**
- Автоматический фейловер лидерства (при проблемах с **Leader** - из **ISR** поднимается новый **Leader**, всё синхронизируется)
-------------------------

```
public enum Partitioner
{
  Random, //Все сообщения равномерно распределяются по партициям
  Consistent, //Все сообщения с Key == null попадут в одну партицию
  ConsistentRandom, //CRC32(Message.Key) -> партиция. Все сообщения с Key == null равномерно распределяются по партициями
  MurMur2, //Другой механизм по получению хэш значения, для совместимости с Java
  MurMur2Random //Другой механизм по получению хэш значения, для совместимости с Java
}
```

- ProduceAsync (await) vs Produce (+callback)

```
public enum Acks : int //гарантия доставки для Producer
{
    None = 0, //подтверждение не отправляется
    Leader = 1, //подтверждение отправляется после того, как лидер записал сообщение в свой локальный лог
    All = -1 //подтверждение отправляется после того, как все реплики в ISR записали сообщение в локальные логи
}
```

```
public enuma CompressionType //разные алгоритмы сжатия сообщений, влияет на производительность (CPU)
{
  None, //по умолчанию
  Gzip,
  Snappy,
  Lz4,
  Zstd
}
```

- Producer выбирает партицию для сообщения
- Producer определяет уровень гарантии доставки
- В Producer можно тюнить производительность

-------------------------

Гарантия обработки для Consumer
-at least once (коммит после обработки сообщения)
-mostly once (коммит до обработки сообщения. Риск того, что при обработке может возникнуть ошибка и будет некорректное поведение с сообщением)

Consumer может делать 1 коммит на 1 сообщение (низкая производительность), но может делать и 1 коммит на N сообщений (высокая производительность) используя функцию StoreOffset

public enum AutoOffsetReset //настройки Consumer по обработке сообщений
{
 Latest = 0, // Consumer при подключении будет обрабатывать только новые сообщения
 Earliest = 1, // Consumer при подключении будет обрабатывать с самых старых сообщений по порядку
 Error = 2 // Consumer при подключении будет обрабатывать с момента, с которого возникла ошибка (редко используется)
}

Consumer Group - несколько Consumer могут быть объединены в группу для параллельного чтения и обработки сообщений (для ускорения производительности)
Consumer Group автоматически читает очередь сообщений (автоматический фейловер)
Независимая обработка разными Consumer Group

-------------------------

Преимущества Kafka
 - Персистентность данных
 - Высокая производительность
 - Независимость пайплайнов обработки
 - Возможность вычитать историю заново
 - Гибкость в использованию (благодаря простоте)

-------------------------

Когда Kafka надо использовать
 - Лямбда и Каппа архитектура
 - Стриминг БОЛЬШИХ данных
 - Много клиентов (много Producer, много Consumer)
 - Требуется кратное масштабирование
 - Велосипедостроение

-------------------------

Недостатки Kafka (чего нет из коробки, но можно реализовать самому)
 - Отложенные сообщения
 - DLQ
 - AMQP/MQTT
 - TTL на сообщение
 - Очереди с приоритетами

-------------------------

**Параметры**
```
retention.bytes = -1 (сколько угодно можно записывать данные в партицию)
retention.ms = 604800000 (время, сколько не удаляется партиция)
replication factor (сколько существует лидер+реплик у партиции)
min.insync.replicas = 2 (минимальное количество лидер+реплик, чтобы сработало Acks.All)
BatchSize = 1000000 (сколько объём в байтах всех сообщений, при котором Producer записывает из буфера в Kafka свои отправляемые сообщения)
BatchNumMessages = 10000 (сколько количество сообщений, при котором Producer записывает из буфера в Kafka свои отправляемые сообщения)
LingerMs = 5 (сколько времени, при котором Producer записывает из буфера в Kafka свои отправляемые сообщения)
EnableAutoCommit = true (автоматический коммит асинхроннм образом)
AutoCommiIntervalMs = 5000 (как часто будет коммитить в Broker)
EnableAutoStoreOffset = true (можно не писать функцию StoreOffset, будет вызываться автоматически)
ClientRack = "DataCenterBrokerName" - в случае кластера и брокеров в разных ДатаЦентрах - возможно настроить Consumer на брокеров своего же датацентра (даже если это будет не Leader) для ускорения производительности
```

-------------------------

Источник: https://www.youtube.com/watch?v=ghKnX5fuW5s 
